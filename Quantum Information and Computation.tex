\documentclass[10pt,a4paper]{article}
\input{./preamble.tex}

\title{Ew Applied Maths}
\begin{document}
\maketitle
\setcounter{section}{-1}

\section{Introduction}
\subsection*{What is information?}
We get information when we acquire knowledge. In classical information, the fundamental unit of information is a bit - a \underline{B}oolean un\underline{it}, which takes values of either $0$ or $1$. If we have a question with $2^n$ possible different, answers, then we can label each answer with a string of $n$ bits.

\subsection*{What is computation?}
Computation can be defined as the processing of information - updating a bit string using a prescribed sequence of steps, which we might call a program. Each of these steps can be the actions of a Boolean gate, such as \textsc{Not}, \textsc{And}, \textsc{Or}.

\subsection*{What is a bit physically?}
Physically a bit is given by any 2 \textit{different} physical states of a system that can be reliably distinguished by some physical measurement. For instance, I can write 0 or 1 in this document, which is stored as data on GitHub or your hard drive, and you can conduct the physical measurement of loading this document and reading the following number: 1. This concept is summed up in the saying ``There is no information without representation". We see that any computation is then the manipulation of a physical system, and so computers must obey the laws of physics. Modern computers obey classical physics (at least for now - please email me / hololens call me if this is not the case for you), but as Feynmann once said: ``Nature isn't classical dammit".

On the atomic and subatomic (and even now molecular) scales, particles are governed by Quantum Mechanics. This has some novel features over classical mechanics, such as the ideas of quantum superposition, entanglement, and quantum measurement. Throughout this course, we will be exploiting these features. They will make things more complicated, but at the same time will give us some advantages in information storage, communication, computation, as well as security/cryptography.

Most of the work for this course was done during the 1980's and 1990's, although the Russian mathematician Alexander Holevo was already working on the ideas of quantum information in the 1970's.

\subsection*{In what ways is QIC better than its classical counterpart?}
A quantum computer cannot compute any computational task which isn't already computable \textit{in principle} by a classical computer. However, some things will require many times the age of the universe to compute even on the fastest of classical supercomputers.

\subsection{Computational Complexity Theory}
We want to have some idea of the ``difficulty" of a computational task. We measure this by the amount required of the two computational resources of time and space. For instance, consider the problem of factoring a number with $n$ digits. Then the input size for the computation is $n$, and we can look at how the time/space grow as functions of $n$.

If the time grows polynomially in $n$, we call this a poly-time algorithm. These are computable in practice. If it grows faster than any polynomial, we call it an exponential-time algorithm, which are, whilst theoretically computable, uncomputable in practice for large inputs. 

Currently, there is no known poly-time factoring algorithm for a classical computer, but in 1994 Peter Shor came up with a poly-time quantum algorithm for integer factorisation.

\subsection{Communication \& Security Issues}
If we use quantum particles as information carriers, we end up with communication possibilities which were the stuff of science fiction previously, such as quantum teleportation, or implement mathematically provably secure communication. 

\subsection{Technological Issue}
Moore's law states that, since 1965, devices will miniaturise by a factor of 4 every 3.5 years. Eventually (and this is already happening), we will get close to quantum scales. For instance, modern CPUs are built by manufacturing machines with a resolution of around 10nm, or 100 atoms across. At these scales, quantum mechanics will start to cause problems for classical computation, so why not embrace this new feature? In reality, the technological barrier to actually using quantum bits (qubits) is huge, and the most advanced current quantum computers have about 53 qubits. Moreover, Google has claimed \emph{quantum supremacy} in demonstrating a task, known as the ``random sampling algorithm", which their quantum computer can complete faster than a classical computer.

\subsection{Quantum Mechanics}
We have 4 key postulates of quantum mechanics:
\begin{itemize}
\item[(QM1)] Describes the quantum state of a physical system, $S$
\item[(QM2)] Describes the joint state of two composite systems, $S_1S_2$
\item[(QM3)] Describes how quantum states evolve throughout time. Here we will be interested in discrete time steps.
\item[(QM4)] Describes how quantum states respond to measurement.
\end{itemize}
The idea behind the mathematics of quantum mechanics, which we'll get to properly in the next section, is that we want to associate to every quantum-mechanical system $S$ a \emph{complex inner product vector space} $\mathcal{V}$, or \emph{Hilbert space}. We will be using \emph{Dirac's bra-ket notation}.

\section{Mathematical Preliminaries \& Bra-Ket Notation}
We will be working in an $n$-dimensional complex inner product spaces $\mathcal{V}$. We will denote a column vector by a \emph{ket}, denoted $\ket{\psi}$. It's conjugate transpose is called a \emph{bra}, and written $\bra{\psi}$. For instance, if $\ket{\psi} = \begin{pmatrix} a \\ b \end{pmatrix}$, then $\bra{\psi} = (\bar{a}, \bar{b})$. We then denote the \emph{inner product} $(\ket{\phi}, \ket{\psi}) = \braket{\phi}{\psi} = (\bar{a}, \bar{b})\begin{pmatrix} c \\ d\end{pmatrix} = \bar{a}c+\bar{b}d \in \C$.

Recall the axioms for an inner product:
\begin{itemize}
\item[IP1] Positive definite. $\R \ni \braket{\psi}{\psi} \geq 0$, and $=0$ if and only if $\ket{\psi} = \mathbf{0}$.
\item[IP2] Linearity in second argument. $\braket{\phi}{\lambda\psi} = \lambda \braket{\phi}{\psi}$
\item[IP3] Antilinearity in first argument. $\braket{\lambda\phi}{\psi} = \bar{\lambda}\braket{\phi}{\psi}$
\item[IP4] Skew-symmetry. $\overline{\braket{\phi}{\psi}} = \braket{\psi}{\phi}$
\item[IP5] Norm. We define $||\psi|| = \sqrt{\braket{\psi}{\psi}}$
\end{itemize}

For this course we will take as a convention that $\mathcal{V} = \C^n$, with basis $\ket{0} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}, \ket{1} = \begin{pmatrix}
0 \\ 1 \end{pmatrix}$, and so on for higher dimensions.

We also have an \emph{outer product}, which is simply the other way round, so that we have $\ket{\psi}\bra{\phi}$ is an $n\times n$ matrix.

Note that this basis is a \emph{complete orthonormal basis} for $\C^n$, i.e. we have $\braket{i}{j} = \delta_{ij}$.

By complete, we mean that $\sum_{i=1}^n \ket{i}\bra{j} = I_{n \times n}$. As an exercise, check that $\mathcal{V} = \C^2$ with basis $\ket{0}, \ket{1}$ is complete.

We will also be using the orthonormal basis $\{\ket{+}, \ket{-}\}$, with $\ket{\pm} = \frac{\ket{0}\pm\ket{1}}{\sqrt{2}}$.

Suppose we have spaces $\mathcal{V}, \mathcal{W}$, of dimensions $n, m$, with bases $\{\ket{e_i}\}_{i=1}^m; \{\ket{f_i}\}_{i=1}^n$. Then we define the \emph{tensor product space} $\mathcal{V} \otimes \mathcal{W}$ to be the $mn$ dimensional vector space with orthonormal basis $\{\ket{e_i}\otimes\ket{f_j}\}_{i,j}$, where we have:
\begin{align*}
\ket{v}\otimes\ket{w} = \begin{pmatrix} a \\ b \end{pmatrix} \otimes \begin{pmatrix} c \\ d \end{pmatrix} = \colvec{a \colvec{c \\ d}\\b \colvec{c\\d}} = \colvec{ac \\ ad\\ bc \\ bd} \in \C^2\otimes \C^2.
\end{align*}

If a vector $\ket{\psi} \in \mathcal{V}\otimes\mathcal{W}$ can be written as $\ket{v}\otimes \ket{w}$, we call it a \emph{product state}. There are some vectors which cannot be expressed in this way. These are called \emph{entangled vectors}. Note that we will often omit the $\otimes$, and just write $\ket{\psi} = \ket{v}\ket{w}$.

We can also take $k$-fold \emph{tensor powers} of $\mathcal{V}$:
\begin{align*}
\mathcal{V}^{\otimes k} \coloneq \mathcal{V}\otimes \mathcal{V}\otimes\ldots \otimes \mathcal{V}
\end{align*}
$\mathcal{V}^{\otimes k}$ is an $n^k$ dimensional vector space. It has a basis $\{\ket{i_1}\ket{i_2}\ldots\ket{i_k} = \ket{i_1i_2\ldots i_k}\}$, where the $\ket{i_j}$ are basis vectors of $\mathcal{V}$. In the case where $\mathcal{V} = \C^2$, we can think of these as bitstrings.

For an example of an entangled vector, consider $\ket{\Phi} = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11}) \in \C^2 \otimes \C^2$. Assume there is $\ket{v} = a\ket{0} + b\ket{1}; \ket{w} = c\ket{0} + d\ket{1}$. Then $\ket{v}\otimes\ket{w} = ac\ket{00}+ad\ket{01}+bc\ket{10}+bd\ket{11}$. But there is no choice of $a, b$ that makes this equal to $\ket{\Phi}$.

If $\ket{\psi_1} = \ket{\alpha_1}\ket{\beta_1}, \ket{\psi_2} = \ket{\alpha_2}\ket{\beta_2}$ are product vectors in $\mathcal{V}\otimes\mathcal{W}$. Then $\braket{\psi_1}{\psi_2} = \braket{\alpha_1}{\alpha_2}\braket{\beta_1}{\beta_2}$. In the case where one of the vectors is not a product vector, we have to write it as a sum of the basis vectors $\ket{e_i}\ket{f_j}$ of $\mathcal{V}\otimes\mathcal{W}$, and then expand that product out.

For example, if $\ket{A} = \sum_{i=1}^m \sum_{j=1}^n a_{ij}\ket{e_i}\ket{f_j}$, and $\ket{B} = \sum\sum b_{ij} \ket{e_i}\ket{f_j}$, then:
\begin{align*}
\braket{A}{B} &= \sum_{i,i'}\sum_{j,j'} a_{ij}^*b_{i'j'} \braket{e_i}{e_i'}\braket{f_j}{f_j'}\\
&= \sum_{i,j} a_{ij}^* b_{ij}
\end{align*} 

\section{Postulates of Quantum Mechanics}
\begin{enumerate}
\item[QM1] To any isolated/closed quantum system, one can associate a Hilbert space $\mathcal{V}$, called the \emph{state space}. The physical states are given by \emph{unit vectors} in $\mathcal{V}$. (More precisely, they are given by \emph{rays}: suppose we have $\ket{\psi}\in \mathcal{V}, \ket{\phi} = e^{\im\theta}\ket{\psi}$ for $\theta \in \R$, where we call $e^{\im\theta}$ a \emph{global phase factor}. We will see that there is no measurement that is able to distinguish $\ket{\phi}, \ket{\psi}$, so to all intents and purposes they are identical - they refer to the same state. Hence we only distinguish state vectors up to the equivalence relation of differing by a global phase factor, and call the equivalence classes the rays)
\end{enumerate}
\end{document}
