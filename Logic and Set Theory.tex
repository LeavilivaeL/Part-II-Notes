\documentclass[10pt,a4paper]{article}
\input{./preamble.tex}

\title{Sogic and Let Theory}
\begin{document}
\maketitle

\section{Propositional Logic}
Let $P$ be a set of \emph{primitive propositions}, i.e. $P$ is a set of symbols with $(, ), \bot, \implies \notin P$. Unless stated otherwise (i.e. that $P$ is uncountable), we may assume that $P = \{p_1, p_2, \ldots \}$.

The set of \emph{propositions}, denoted by $L(P)$ or simply just $L$, is defined inductively as follows:
\begin{enumerate}
\item $P \subset L$
\item $\bot \in L$, called \false
\item if $p, q \in L$, then $(p \implies q) \in L$
\end{enumerate}

Each proposition is a string of symbols from $P \cup \{(,),\bot,\implies\}$, for instance we have the propositions $p_1, (p_1 \implies p_1), ((p_1\implies p_2)\implies(p_2 \implies(\bot \implies p_3)))$. For readability, we often draw symbols $(,)$ in different ways, for instance as $[, (, \Big($.

Sometimes we omit the outside pair of parentheses when writing down propositions, for instance $p_1 \implies p_2$ is shorthand for $(p_1 \implies p_2)$.

Also we use some abbreviations, e.g.:
\begin{itemize}
\item[\textsc{Not:}] $\neg p$ to mean $(p \implies \bot)$
\item[\textsc{Or:}] $p \lor q$ to mean $(\neg p \implies q)$
\item[\textsc{And:}] $p \land q$ to mean $\neg(\neg p \lor \neg q)$
\end{itemize}

What do we mean by $L$ ``defined inductively"? Define $L_0 = P \cup \{\bot\}$. Then, given $L_n$, we can define $L_{n+1} = L_{n-1} \cup \{(p\implies q) : p, q \in L_{n-1}\}$. Then we set $L = \bigcup_{n=0}^{\infty} L_n$. Note: if $p \in L \setminus(P \cup \{\bot\})$, then it is easy to show that there are \emph{unique} $q, r \in L$ with $p = (q \implies r)$.

\subsection{Semantic Entailment}
A \emph{valuation} is a function $v: L \to \{0,1\}$ satisfying:
\begin{enumerate}
\item $v(\bot) = 0$
\item For all $p, q \in L, v(p\implies q) = \begin{cases} 0 & v(p) = 1, v(q) = 0 \\ 1 & \ow \end{cases}$.
\end{enumerate}
If $p \in L$ and $v(p) = 1$ for every valuation, we say that $p$ is a \emph{tautology}, and write $\taut p$.

\underline{Examples:}
\begin{enumerate}
\item $\taut (p \implies p)$

\begin{tabular}{c|c}
$v(p)$ & $v(p\implies p)$ \\\hline
0 & 1 \\
1 & 1
\end{tabular}

So this is a tautology.

\item $\taut (p \implies (q \implies p))$

\begin{tabular}{c|c|c|c}
$p$ & $q$ & $q \implies p$ & $p \implies (q \implies p)$\\\hline
0 & 0 & 1 & 1\\
0 & 1 & 0 & 1\\
1 & 0 & 1 & 1\\
1 & 1 & 1 & 1
\end{tabular}

So this is a tautology.

\item Is $\taut (p \implies (q \implies r)) \implies ((p\implies q)\implies(p \implies r))$?

Suppose not. Then for some $p,q,r$ and valuation $v$ we have:

\hspace*{1cm}$v(p \implies (q\implies r)) = 1$\\
\hspace*{1cm}$v((p\implies q)\implies(p \implies r)) = 0$.

So $v(p \implies q) = 1, v(p \implies r) = 0$. Hence $v(p) = 1, v(r) = 0, v(q) = 1$. But then $v(q \implies r) = 0$, and so $v(p \implies(q\implies r)) = 0 \contr$.

\item $\taut ((p \implies \bot) \implies \bot) \implies p$, i.e. $ \neg \neg p \implies p$, i.e. $(\neg p \lor p)$. This is the Law of the Excluded Middle, and is also a tautology.
\end{enumerate}
Note that a valuation is entirely determined by its values on the primitive propositions.
\begin{proposition}
\item
\begin{enumerate}
\item Let $v, w: L \to \{0,1\}$ be valuations with $v|_P = w|_P$. Then $v=w$.
\item Let $f:P \to \{0,1\}$. Then there is a valuation $v:L \to \{0,1\}$ with $v|_P = f$.
\end{enumerate}
\end{proposition}
\begin{proof}\item
\begin{enumerate}
\item We prove this by induction on $n$, so that $v|_{L_n} = w|_{L_n}$. For the base case of $n=0$, $v|_P = w|_P$, and $v(\bot) = 0 = w(\bot)$. Then for the induction step, $v|_{L_{n-1}} = w|_{L_{n-1}}$. Let $p \in L_n \setminus L_{n-1}$. Then $p = (q \implies r)$ for some $q, r \in L_{n-1}$. We know that $v(q) = w(q), v(r) = w(r)$, and so $v(p) = w(p)$.

\item We define $v$ successively on $L_0, L_1, L_2, \ldots$
\begin{itemize}
\item[$L_0$:] Let $v|_P = f$ and let $v(\bot) = 0$
\item[$L_n$:] If $p \in L_n \setminus L_{n-1}$, then $p = (q \implies r)$, and so set $v(p)$ to be 0 if $v(q) = 1, v(r) = 0$, and $1$ otherwise. Since propositions are built up in a unique way, this is indeed a valuation.
\end{itemize}
\end{enumerate}
\end{proof}

Let $S \subset L$. We say that $v$ is a \emph{model} of $S$ if $v$ is a valuation with $v(x) = 1$ for all $x \in S$. If $S = \{p\}$, we say that $v$ is a model of $p$. If every model of $S \subset L$ is a model of $p \in L$, we say that $S$ \emph{semantically entails} $p$, and write $S \taut p$. Note that $\emptyset \taut p$ is exactly the same as $\taut p$.

For example, $\{p, p\implies q\} \taut q$.

\subsection{Syntactic Entailment (Provability)}
Our proof system will have axioms as follows for all $p, q, r \in L$:
\begin{enumerate}
\item[A1] $p \implies (q \implies p)$
\item[A2] $(p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))$
\item[A3] $((p \implies \bot) \implies \bot)\implies p$
\end{enumerate}
Our proof system also has a \emph{deduction rule} known as \emph{modus ponens} (MP): for all $p, q \in L$, from $p$ and $(p \implies q)$ we can deduce $q$.

Note that each axiom is a tautology. For MP, see the last example of \textbf{\textsection 1.1}

Let $S \subset L$ and $p \in L$. A \emph{proof} of $p$ from $S$ is a sequence $t_1, t_2, \ldots, t_n \in L$ of finite length with $t_n = p$ such that, for each $i$, either $t_i$ is an axiom, or $t_i \in S$ (a \emph{hypothesis}), or there exist $j, k < i$ with $t_k = (t_j \implies t_i)$.

If there exists a proof of $p$ from $S$, we say that $S$ \emph{syntactically entails} $p$, or $S$ \emph{proves} $p$, and we write $S \vdash p$. If $S = \emptyset$, we say $p$ is a \emph{theorem} and write $\vdash p$.

\underline{Example: $\vdash (p \implies p)$}\\
Use A2, with $r=p$, to get $(p \implies (q\implies p)) \implies ((p \implies q) \implies (p \implies p))$. Now the first bracket is a theorem by A1, and if we take $q = (p \implies p)$ in the second, we can use modus ponens twice with A1 to deduce the final bracket, that $(p \implies p)$. We will write this formally:

\begin{lemma}
For all $p \in L, \vdash (p \implies p)$
\end{lemma}
\begin{proof}
\item
\begin{enumerate}
\item $(p \implies ((p \implies p) \implies p)) \implies ((p \implies (p\implies p))\implies (p \implies p))$ \hfill (A2)
\item $p \implies ((p \implies p)\implies p)$ \hfill (A1)
\item $(p \implies (p \implies p)) \implies (p \implies p)$ \hfill (MP on 1, 2)
\item $p \implies (p \implies p)$ \hfill (A1)
\item $p \implies p$ \hfill (MP on 3, 4)
\end{enumerate}
\end{proof}
\begin{proposition}[The Deduction Theorem]
Let $S \subset L$ and $p, q \in L$. Then $S \vdash (p \implies q)$ if and only if $S \cup \{p\} \vdash q$.
\end{proposition}
\begin{proof}
Suppose $t_1, \ldots, t_n$ is a proof of $p \implies q$ from $S$. Then $t_1, \ldots, t_n, p, q$ is a proof of $q$ from $S \cup \{p\}$. Suppose that $t_1, \ldots, t_n$ instead is a proof of $q$ from $S \cup \{p\}$. We show by induction on $i$ that $S \vdash (p \implies t_i)$ for each $i$, and then we will be done since $t_n = q$.
\begin{enumerate}
\item If $t_i \in S$:
\begin{itemize}
\item $t_i \implies (p \implies t_i)$ \hfill (A1)
\item $t_i$ \hfill (hypothesis)
\item $(p \implies t_i)$ \hfill (MP)
\end{itemize}
\item If $t_i = p$, use Lemma \textbf{1.2}
\item If $t_k = (t_j \implies t_i)$ for some $j, k < i$, then write down proofs of $(p \implies t_j), (p \implies t_k)$ from $S$. Then append:
\begin{itemize}
\item $(p \implies (t_j \implies t_i)) \implies ((p \implies t_j) \implies (p \implies t_i))$ \hfill (A2)
\item $(p \implies t_j) \implies (p \implies t_i)$ \hfill (MP)
\item $p \implies t_i$ \hfill (MP)
\end{itemize}
\end{enumerate}
\end{proof}

\subsection{The Completeness Theorem and Applications}
The key result of this section will be that $\taut$ and $\vdash$ coincide. There will be two directions to prove:
\begin{enumerate}
\item \emph{Soundness:} If $S \vdash p$ then $S \taut p$.
\item \emph{Adequacy:} If $S \taut p$ then $S \vdash p$.
\end{enumerate}
\begin{proposition}[Soundness Theorem]
Let $S \subset L$ and $p \in L$ with $S \vdash p$. Then $S \taut p$.
\end{proposition}
\begin{proof}
Let $t_1, \ldots, t_n$ be a proof of $p$ from $S$. Let $v$ be a model of $S$. We show by induction on $i$ that $v(t_i) = 1$ for $1 \leq i \leq n$.

If $t_i \in S$ then $v(t_i) = 1$. If $t_i$ is an axiom then $\taut t_i$ so $v(t_i) = 1$. Otherwise, $t_k = (t_j \implies t_i)$ for some $j, k < i$. By the induction hypothesis, $v(t_j) = v(t_j \implies t_i) = 1$, so $v(t_i) = 1$.
\end{proof}

For adequacy, first consider the special case $p = \bot$, i.e. ``If $S \taut \bot$ them $S \vdash \bot$". We will prove the contrapositive: ``If $S \nvdash \bot$ then $S \ntaut \bot$". If $S \nvdash \bot$ we say that $S$ is \emph{consistent}. $`S \taut \bot$" means ``if $v$ is a model of $S$ then $v(\bot)=1$". But $v(\bot) = 0$ for every valuation $v$, so this says ``$S$ has no model." Hence ``$S \ntaut \bot$" says ``$S$ has a model".

\begin{theorem}[Model Existence Lemma]
Let $S \subset L$ be consistent. Then $S$ has a model.
\end{theorem}
\begin{proof}[Proof in the case P is countable]
$L$ is countable, as each $p \in L$ is a finite string of symbols from $P \cup \{(,),\bot,\implies\}$.

We write $L = \{x_1, x_2, \ldots\}$. We shall recursively construct sets $S_n \subset L$ with $S=S_0 \subset S_1 \subset\ldots$ and $S_n$ consistent.

The base case is trivial, as $S_0 = S$ is consistent by hypothesis. Then for $n>0$, we have $S_{n-1}$ consistent. If $S_{n-1} \cup \{\neg x_n\}$ is consistent, let $S_n = S_n\cup \{\neg x_n\}$. Otherwise, $S_{n-1} \cup \{\neg x_n\} \vdash \bot$, and by the deduction theorem, $S_{n-1} \vdash (\neg x_n \implies \bot)$, i.e. that $S_{n-1} \vdash \neg \neg x_n$. But $S_{n-1} \vdash (\neg\neg x_n \implies x_n)$ by (A3), and so $S_{n-1} \vdash x_n$ by (MP). But $S_{n-1}$ is consistent, so let $S_n = S_{n-1} \cup \{x_n\}$.

Then let $\bar{S} = \bigcup_{n=1}^{\infty} S_n$. Firstly, $S_n$ is consistent - suppose $t_1, \ldots, t_n$ is a proof of $\bot$ from $\bar{S}$. Then there is some collection $i_1, \ldots, i_m \in \N$ such that the hypotheses used in the proof come from $S_{i_1}, \ldots, S_{i_m}$. Let $I = \max\{i_1, \ldots, i_m\}$. Then every hypothesis comes from $S_I$, and so $t_1, \ldots, t_n$ is a proof of $\bot$ from $S_I$. \contr

Also, for every $p \in L$ we have $p \in \bar{S}$ or $\neg p \in \bar{S}$. Moreover, $\bar{S}$ is \emph{deductively closed} (d.c): if $\bar{S} \vdash p$ then $p \in \bar{S}$. Indeed, suppose that $\bar{S} \vdash p$ but $p \notin \bar{S}$. Then $\neg p \in \bar{S}$. Now $\bar{S} \vdash p$ and $\bar{S} \vdash \neg p$, i.e. $\bar{S} \vdash (p \implies \bot)$. So by (MP), $\bar{S} \vdash \bot$ \contr. 

Now let $v: L \to \{0,1\}$ be the indicator function of $\bar{S}$. We must check that $v$ is a valuation. As $\bar{S}$ is consistent, it is certainly true that $\bot \notin \bar{S}$, and so $v(\bot) = 0$. 

Let $p, q \in L$. We want to think about $(p \implies q)$:
\begin{itemize}
\item[Case 1.] Suppose $v(q) = 1$. Then $q \in \bar{S}$, so $\bar{S} \vdash (p \implies q)$, but $\bar{S}$ is deductively closed, and so $(p \implies q) \in \bar{S}$, and $v(p \implies q) = 1$.

\item[Case 2.] Suppose $v(p) = 0$. Again, we must show that $v(p \implies q) = 1$, i.e. that $\bar{S} \vdash (p \implies q)$. By the Deduction Theorem, this is equivalent to $S\cup \{p\} \vdash q$, and $p \notin S$, so $\neg p \in S$ and it will be enough to show that $\{p, \neg p\} \vdash q$. We have:
\begin{enumerate}
\item $(p \implies \bot)$ \hfill (hyp)
\item $p$ \hfill (hyp)
\item $\bot$ \hfill (MP on 1,2)
\item $((q \implies \bot)\implies \bot) \implies q$ \hfill (A3)
\item $\bot \implies ((q\implies \bot)\implies \bot)$ \hfill (A1)
\item $(q \implies \bot) \implies \bot$ \hfill (MP on 3,5)
\item $q$ \hfill (MP on 4,6)
\end{enumerate}
\item[Case 3.] $v(p) = 1, v(q) = 0$. We want to show that $v(p \implies q) = 0$. Suppose instead that $v(p \implies q) = 1$, so that $(p \implies q) \in \bar{S}, p \in \bar{S}$. But then by (MP) $\bar{S} \vdash q$, so $q \in \bar{S}$, so $v(q) = 1$. \contr
\end{itemize}
We have now shown that $v$ is a valuation. Moreover, $S \subset \bar{S}$ so $v(p) =1$ for all $p \in S$. Hence $v$ is a model of $S$.
\end{proof}

\begin{corollary}[The Adequacy Theorem]
Let $S \subset L$ and $p \in L$ with $S \taut p$. Then $S \vdash  p$.
\end{corollary}
\begin{proof}
Suppose $v$ is a model of $S \cup \{\neg p\}$. Then $v(p) = 1$ and $v(\neg p) = 1$, so $v(\bot) = 1$ \contr. So $S \cup \{\neg p\}$ has no model, and so by the model existence lemma it is inconsistent. That is, $S \cup \{\neg p\} \vdash \bot$. Then by the deduction theorem, $S \vdash (\neg p \implies \bot)$, i.e. $S \vdash \neg \neg p)$, and hence $S \vdash p$.
\end{proof}
\begin{theorem}[The Completeness Theorem]
Let $S \subset L$ and $p \in L$. Then $S \taut p$ if and only if $S \vdash p$.
\end{theorem}
\begin{proof}
Soundness and adequacy.
\end{proof}
Two important applications:
\begin{corollary}[Compactness Theorem]
Let $S \subset L$ such that every finite subset of $S$ has a model. Then $S$ has a model.
\end{corollary}
\begin{proof}
Not at all obvious a priori, but obvious if we replace ``has a model" by ``is consistent". If $S$ is not consistent, then $S \vdash \bot$, so, as proofs are finite, $T \vdash \bot$ for some finite $T \subset S$, so $T$ is inconsistent.
\end{proof}
\begin{corollary}[The Decidability Theorem]
Let $S \subset L$ be finite and $p \in L$. Then there is an algorithm to determine in finite time whether or not $S \vdash p$.
\end{corollary}
\begin{proof}
Obvious if we replace $\vdash$ by $\taut$, and then do a truth table.
\end{proof}
\subsection{What happens when P is uncountable?}
This will be just a sketch - it will be a while before we can do this properly in chapter 3. We have only proved the completeness theorem under the assumption that $P$ is countable. However, we only used this when showing that, if $S$ is consistent, then there is a consistent $\bar{S} \supset S$ with $p \in \bar{S}$ or $\neg p \in \bar{S}$ for all $p \in L$.

We needed $P$ to be countable so that $L = \{x_1, x_2, \ldots\}$ is countable and we can consider the $x_is$ in turn, deciding if $x_i \in \bar{S}$ or $\neg x_i \in \bar{S}$.

Can we do without this assumption? Now allow $P$, and hence $L$, to be uncountable. Let $S \subset L$ be consistent and look for $\bar{S} \supset S$ consistent with $p \in \bar{S}$ or $\neg p \in \bar{S}$ for all $p \in L$. We could try $\bar{S} = S$, and if it works then we are done.

Otherwise, there is some $x_0 \in L$ with $x_0 \notin \bar{S}$ and $\neg x_0 \notin \bar{S}$. Exactly as in the countable case, either $\bar{S}\cup\{x_0\}$ or $\bar{S} \cup \{\neg x_0\}$ is consistent. So add $x_0$ or $\neg x_0$ to $\bar{S}$, keeping it consistent. If $\bar{S}$ works now, then we're done, otherwise there is some $x_1 \in L$ with $x_1 \notin \bar{S}$ and $\neg x_1 \notin \bar{S}$, and so on and so forth. If this never terminates, then we keep on going forever.

If after we've done this infinitely many times, if we are done the stop. Otherwise, we have $x_{\omega}$ with $x_{\omega} \notin \bar{S}$ and $\neg x_{\omega} \notin \bar{S}$, so either add $x_{\omega}$ or $\neg x_{\omega}$ to $\bar{S}$. If we're not done there is another $x_{\omega+1}$ and so on.

Either eventually we finish, or we have to go on forever, until we get to $x_{\omega\cdot 2}$, and then keep on going\ldots

If this never terminates, we get loads and loads of $x_is$. What are they being indexed by? It looks to be some sort of extension of $\N$.:
\begin{align*}
0,1,2,3,4,\ldots,\omega,\omega+1,\omega+2,\ldots,\omega2,\omega2+1,\ldots,\omega3,\ldots,\omega4,\ldots,\\\omega^2,\omega^2+1,\ldots,\omega^2+\omega,\ldots,\omega^22,\ldots, \omega^3,\ldots,\omega^4,\ldots,\omega^\omega,\ldots,\omega^{\omega^\omega},\ldots,\omega^{\omega^{\omega^{\iddots}}}=\epsilon_0,\ldots
\end{align*}
This is only countably many ordinals, but in fact if we keep on going, we can get to uncountably many numbers. We call these indices \emph{ordinals}, and we will define them in chapter 2 in such a way that:
\begin{itemize}
\item 0 is an ordinal
\item For any ordinal $\alpha$ there is a least ordinal larger than it
\item Given any set of ordinals, there is a least ordinal bigger than all of them
\end{itemize}
We will use Hartog's Lemma to show that in fact, eventually we do run out of stuff in $L$ if we use this indexing, which says that, for any set $X$, there are more ordinals than there are elements of $X$.

Note that here we are using the axiom of choice, because this is part of the maths tripos which uses the axiom of choice. Later on we, will think about what might happen if we don't have the axiom of choice, but we won't worry about that for now.

\section{Ordinals}
\subsection{Functions and Relations}
A \emph{function} $f:X \to Y$ from a set $X$ to a set $Y$ is a subset $f \subset X\times Y$ such that for all $x \in X$ there is a unique $y \in Y$ with $(x,y) \in f$. We write $f(x) = y$ to mean $(x,y) \in f$. If $Z \subset X$, the \emph{restriction} of $f$ to $Z$ is the function $f|_Z:Z\to Y$ given by $f|_Z = f \cap (Z\times Y)$.

If $f^{-1}(\{y\}) = \{x \in X: f(x) = y\}$ has at most one element for every $y \in Y$, we say $f$ is an \emph{injection} (i.e. no two $x$'s get mapped to the same $y$). If $f^{-1}(\{y\})$ has at least one element for every $y \in Y$, we say $f$ is a \emph{surjection} (i.e. every $y$ gets mapped to by some $x$). If $f$ is both an injection and a surjection, it is called a \emph{bijection}.

A \emph{relation} $R$ on a set $X$ is a subset $R \subset X \times X$. We write $xRy$ to mean $(x,y) \in R$. If $R, S$ are relations on sets $X, Y$ respectively, an \emph{isomorphism} from $(X,R)$ to $(Y,S)$ is a bijection $f:X \to Y$ such that, for all $x, y \in X, xRy \iff f(x)Sf(y)$. If such an isomorphism exists, we say that $(X,R)$ and $(Y,S)$ are \emph{isomorphic}.

Note: this is not the right way to think about functions and relations, but it is convenient sometimes. Keep thinking of a function as ``something that associates a unique element of $Y$ with each element of $X$". Note that this does give us a way to define functions and relations in such a way that they live in the universe of sets.

\subsection{Well-Ordering}
A \emph{total order} on a set $X$ is a relation $<$ on $X$ satisfying:
\begin{itemize}
\item For all $x, y \in X$, precisely one of $x=y, x<y, y<x$ holds. \hfill(trichotomy)
\item Fro all $x,y,z \in X$, if $x<y$ and $y<z$ then $x<z$. \hfill(transitivity)
\end{itemize}
If $<$ is a total order on $X$, we can define a relation $\leq$ on $X$ by $x\leq y$ if $x<y$ or $x=y$. This satisfies:
\begin{itemize}
\item For all $x,y \in X, x\leq y$ or $y \leq x$.
\item For all $x,y \in X$, if $x\leq y$ and $y\leq x$, then $x=y$.
\item For all $x,y,z \in X$, if $x\leq y, y\leq z$, then $x \leq z$.
\end{itemize}
Conversely, given a relation $\leq$ satisfying these conditions, we can define a total order $<$ on $X$ by $x<y$ if $x\leq y$ and $x \neq y$. Some sources will define $\leq$ to be a total order, but here we will use the $<$ version.

A total order of $X$ is a \emph{well-ordering} of $X$ if every non-empty subset $Z \subset X$ has a least element (i.e. an element $y \in Z$ such that for all $x \in Z, y \leq x$.

An \emph{ordinal} is a well-ordered set with isomorphic sets considered to be the same. Given a well-ordered set $X$, the \emph{order-type} of $X$ is the corresponding ordinal.

A total order $<$ is a well-ordering if and only if there is no infinite descending sequence $x_1 > x_2 > \ldots$.

\hspace*{-1em}\underline{Examples:}
\begin{enumerate}
\item $X = \{a,b,c,d\}$ with $a<b,c,d; b<c,d; c<d$ well orders $X$.
\item The usual order on $\N, \Z, \Q, \R$ defines a total order. $\N$ is well ordered by this, $\Z,\Q,\R$ are not, as $-1>-2>-3>\ldots$.
\item $x<y$ if $|x|-\frac{1+\sgn x}{4} < |y|-\frac{1+\sgn y}{4}$ is however a well ordering on $\Z$, with $0<1<-1<2<-2<\ldots$.
\item Take $\{\frac1n: n \in\N\setminus\{0\}\}$ with the usual ordering. This is not a well ordering, as $1>\frac12>\frac13>\ldots$.
\item Take $\{-\frac1n: n \in\N\setminus\{0\}\}$ with the usual ordering. This is a well ordering, as there are only finitely many elements less than any given element. This has the same order type as $\N$ with the usual order.
\item What about $X = \big\{-\frac1n: n \in \N\setminus\{0\}\big\}\cup\big\{1-\frac1n:n \in \N\setminus\{0\}\big\}$ with the usual order. Even though there are infinitely many elements less than say $\frac23$, we can see that any descending sequence can have only finitely many positive terms, before a negative term, and then only finitely many negative terms. Hence this is in fact a well-ordering, but it is not the same order-type as $\N$. This should remind you of the discussion at the end of section 1, where we went through infinitely many elements, and then did it again.
\end{enumerate}

Let $X$ be a well-ordered set. An \emph{initial segment} of $X$ is a subset $Z \subset X$ such that if $z \in Z$ and $x \in X$ with $x \leq z$ then $x \in Z$. If $Y$ is also a well-ordered set, then we say $Y \leq X$ if $Y$ is isomorphic to some initial segment of $X$. We make some remarks about this notion:
\begin{enumerate}
\item If $Z \neq X$ is an initial segment of $X$ then $X \setminus Z \neq 0$ so has some least element $x$. Then $Z = \{y \in X: y<x\} = X_{(<x)}$.
\item Clearly $X \leq X$.
\item This also gives a definition of $\alpha \leq \beta$ for ordinals $\alpha, \beta$. (We should really check that this is well-defined: i.e. if $Y \leq X$ and $Y' \cong Y, X' \cong X$, then $Y' \leq X'$. This is obvious though because the definition is given in terms of isomorphism, which is transitive).
\item Transitivity is clear, as $\alpha \leq\beta, \beta\leq \gamma \implies \alpha \leq \gamma$. What about trichotomy?
\end{enumerate}
We will generalize two important concepts from $\N$ - the ideas of \emph{induction} and \emph{recursion}
\begin{proposition}[Proof by Induction]
Let $X$ be a well ordered set and let $P(x)$ be a statement about $x \in X$. Suppose for all $x \in X$ that $(\forall y < x, P(y)) \implies P(x)$. Moreover, suppose for $z = \min X$ that $P(z)$. Then $\forall x \in X, P(x)$.
\end{proposition}
\begin{proof}
Suppose not. Then the set $\{x \in X: \neg P(x)\}$ is non-empty, so has a least element $x$, which is strictly greater than $z$. Then $\forall y < x, P(y)$ but $\neg P(x)$. \contr
\end{proof}
\begin{proposition}
Let $X$ be a well-ordered set and $f:X \to Z$ be an isomorphism from $X$ to an initial segment $Z$ of $X$. Then $f$ is the identity function on $X$, and in particular $X \nless X$.
\end{proposition}
\begin{proof}
We prove this by induction on $x$ that $\forall x \in X, f(x)=x$. Indeed, suppose that $x \in X$ and $f(y)=y$ for all $y < x$. As $f$ is injective, $f(x) \geq x$; if $f(x)>x$ then, as $Z$ is an initial segment and $f$ is surjective onto $Z$ we have $f(z) = x$ for some $z > x$, so $f(z) = x < f(x)$, but $x < z$. \contr
\end{proof}

What about recursion? We want to generalise things like ``define $f: \N \to \N$ recursively by $f(0)=1$ and $f(n) = \sum_{i=0}^{n-1}f(i)$ for $n > 0$".

\begin{proposition}[Definition by Recursion]
Let $X$ be a well-ordered set, let $Y$ be a set, and let $G:\powset (X\times Y) \to Y$. Then there is a unique function $f:X \to Y \st \forall x \in X, f(x) = G(f|_{X_{(<x)}})$.
\end{proposition}
\begin{proof}
For uniqueness, suppose functions $f, f'$ both have this property. We show by induction that $\forall x \in X, f(x) = f'(x)$. Indeed, suppose $x \in X$ and $f(y) = f'(y)$ for all $y < x$. Then $f(x) = G(f|_{x_{(<x)}}) = G(f'|_{(X_{(<x)}}) = f'(x)$.

For existence, define $h$ is an \emph{attempt} at $f$ to mean $h:Z \to Y$ for some initial segment $Z$ of $X$ with $\forall x \in Z, h(x) = G(h|_{Z_{(<x)}})$. Suppose that $h:Z \to Y$ and $h':Z'\to Y$ are attempts. Then $Z \subset Z'$ or $Z' \subset Z$, \textsc{wlog} take the first. Then $h'|_Z$ is an attempt with domain $Z$, and so by uniqueness $h'|_Z = h$. So attempts agree at any points where they are both defined.

Next we will prove by induction that, $\forall x \in X$, there is some attempt $h_x$ with $x \in \dom (h_x)$. Indeed, let $x \in X$ and suppose that, for all $y <x$, $h_y$ is an attempt with $y \in \dom (h_y)$. Let $h = \bigcup_{y<x} h_y$. Then by what we've' just done, $h$ is a function. Indeed, $h$ is an attempt and $X_{(<x)} \subset \dom(h)$. 

If $x \in \dom(h)$, set $h_x = h$. If $x \notin \dom(h)$ then $\dom(h) = X_{(<x)}$. Then we can set $h_x = h\cup \{(x, G(h|_{X_{(<x)}})\}$. Finally, let $f = \bigcup_{x \in X} h_x$.
\end{proof}

\begin{proposition}
Let $X,Y$ be well-ordered sets with $Y \nleq X$, then $X \leq Y$.
\end{proposition}
\begin{proof}
Define $f:X\to Y$ recursively by letting $f(x)$ be the least element of $Y \setminus\{f(w): w \in X, w< x\}$. This set is nonempty as $Y \nleq X$. Then $f$ is an isomorphism from $X$ to an initial segment of $Y$.
\end{proof}
\begin{proposition}[Trichotomy]
Let $\alpha, \beta$ be ordinals. Then $\alpha \leq \beta$ or $\beta \leq \alpha$, and if both hold then $\alpha = \beta$.
\end{proposition}
\begin{proof}
The first part follows immediately from \textbf{2.4}. For the second part, suppose we have isomorphisms $f:\alpha \to B, g:\beta \to A$ where $A,B$ are initial segments of $\alpha, \beta$ respectively. Then $f \circ g$ is an isomorphism from $\beta$ to some initial segment of itself. Then by \textbf{2.2} $f\circ g$ is the identity function on $\beta$. Hence $B = \beta$, and so $\alpha \cong \beta$, so $\alpha = \beta$.
\end{proof}
\begin{theorem}
Let $\alpha$ be an ordinal. Then the ordinals less than $\alpha$ form a set well ordered by $<$.
\end{theorem}
\begin{proof}
The ordinals less than $\alpha$ are precisely the order types of the proper initial segments $\alpha_{(<x)}$ for $x \in \alpha$ of $\alpha$. Then $\bar{\alpha} = \{\alpha_{(<x)} : x \in \alpha\}$ is isomorphic to $\alpha$ via $\alpha \to \bar{\alpha}, x \to \alpha_{(<x)}$. Thus $\bar{\alpha}$ is well-ordered.
\end{proof}
Note that we can write $I_{\alpha}$ for the set of ordinals less than $\alpha$. Then $I_\alpha$ has order type $\alpha$.
\begin{corollary}
Any non-empty set $X$ of ordinals has a least element.
\end{corollary}
\begin{proof}
$X \neq \emptyset$ so there is some $\alpha \in X$. If $\alpha$ is the least element of $X$ then we're done. Otherwise $X \cap I_{\alpha} \neq \emptyset$. But $I_\alpha$ is well-ordered so $X \cap I_\alpha$ has a least element, which must also be the least element of $X$.
\end{proof}
This would lead us to want to say something along the lines of ``the ordinals are well-ordered by <". However:
\begin{theorem}[Burali-Forti Paradox]
The ordinals do not form a set.
\end{theorem}
\begin{proof}
Suppose $X$ is the set of ordinals. Then $X$ is well ordered by $<$ so has order type $\alpha$ for some $\alpha \in X$. But $I_\alpha$ also has order type $\alpha$, and this is a proper initial segment of $X$. So $X$ is isomorphic to a proper initial segment of itself, contradicting \textbf{2.2}.\contr
\end{proof}
\subsection{Ordinal Arithmetic}
Let $\alpha, \beta$ be ordinals. We define $\alpha+\beta$ to be the set $\alpha$ followed by $\beta$, and $\alpha\beta$ to be $\alpha$ followed by itself $\beta$ times.

More precisely, $\alpha+\beta$ is the order type of the set $(\{0\}\times \alpha)\cup (\{1\}\times \beta)$ ordered by $(i,x) < (j,y)$ if and only if $i<j$ or ($i=j$ and $x<y$), whilst $\alpha\beta$ is the order type of the set $\alpha \times \beta$ ordered by $(x,y)<(z,y)$ if and only if $y<w$ or ($y=w$ and $x<z$).

As an exercise, check that these two orderings are indeed well-orderings, so that these definitions make sense.

Suppose that, for each $n \in \N$, we identify $n$ with the ordinal well-ordering on an $n$-element set. Then these definitions generalise arithmetic in $\N$. 
\begin{figure}[H]
\centering
\begin{tikzpicture}
\node at (0,0) {$2+3 = $};
\node[draw, circle, fill, red] at (1,0) {};
\node[draw, circle, fill, red] at (2,0) {};
\node[draw, circle, fill, blue] at (3,0) {};
\node[draw, circle, fill, blue] at (4,0) {};
\node[draw, circle, fill, blue] at (5,0) {};
\node at (5.7,0) {$=5$};
\node at (0,-1) {$2\cdot 3 = $};
\node[draw, circle, fill, red] at (1,-1) {};
\node[draw, circle, fill, red] at (2,-1) {};
\node[draw, circle, fill, blue] at (3,-1) {};
\node[draw, circle, fill, blue] at (4,-1) {};
\node[draw, circle, fill, green] at (5,-1) {};
\node[draw, circle, fill, green] at (6,-1) {};
\node at (6.7,-1) {$=6$};
\end{tikzpicture}
\end{figure}

+ is associative immediately from the definitions. However, if $\omega$ is the order type of $\N$, then $1+\omega = \omega$ under the isomorphism ``subtract 1", however $\omega+1$ would have $\omega$ as an initial segment, and so $1+\omega \neq \omega+1$. As an exercise (see sheet 2), think about whether multiplication is associative, commutative, or distributive.

\subsection{Ordinal Arithmetic II - Attack of the Ordinals}
There is an alternative approach, using ideas of induction and recursion. First, we will need some preliminary ideas.

\begin{proposition}
\item
\begin{enumerate}
\item Let $\alpha$ be an ordinal. Then there is a least ordinal $\beta > \alpha$.
\item Let $X$ be a set of ordinals. then there is a least ordinal $\gamma$ with $\gamma >\delta$ or all $\delta \in X$.
\end{enumerate}
\end{proposition}
\begin{proof}
\item
\begin{enumerate}
\item Take $\beta$ to be $\alpha$ with a single additional element added greater than everything in $\alpha$.
\item Let $Y = \{I_{\delta} : \delta \in X\}$. Then $X$ is the set of order types of elements of $Y$ and the elements of $Y$ are nested sets of ordinals. So take $gamma$ to be the order type of $\bigcup_{\delta \in X} I_{\delta}$.
\end{enumerate}
\end{proof}

In \textit{1.}, we write $\beta = \alpha^{+}$, the \emph{successor} of $\alpha$. In \textit{2}, we write $\gamma = \sup(X)$, the \emph{supremum} of $X$. If $\alpha = \beta^{+}$ for some ordinal $\beta$, we say $\alpha$ is a \emph{successor ordinal}, and otherwise $\alpha$ is a \emph{limit ordinal}. For example, $0$ is a limit, $n \in \N$ is a successor, $\omega$ is a limit. Note that $\alpha$ is a limit if and only if $\alpha = \sup(I_{\alpha})$.

When doing induction or recursion for ordinals, we often deal with successors and limits in separate cases. We often treat $0$ as different to other limits as well.

We can then define addition and multiplication for ordinals recursively as follows:
\begin{itemize}
\item $\alpha + 0 = \alpha$
\item $\alpha + \beta^{+} = (\alpha + \beta)^{+}$
\item $\alpha + \gamma = \sup\{\alpha + \delta : \delta < \gamma\}$
\item $\alpha \cdot 0 = 0$
\item $\alpha \cdot \beta^{+} = \alpha \cdot \beta + \alpha$
\item $\alpha \cdot \gamma = \sup\{\alpha\delta : \delta < \gamma\}$.
\end{itemize}

However we have a problem - recursion doesn't work here since the ordinals do not form a set. We can get around this though.

Let $\alpha$ be an ordinal and suppose we want to define $\alpha + \beta$ for all ordinals $\beta$. Given an ordinal $\gamma$ we can define $\alpha + \beta$ recursively for all $\beta \in I_{\gamma}$ as above, since $I_{\gamma}$ is a set. Suppose we restrict this definition to $\beta \in I_{\gamma'}$ for some $\gamma' < \gamma$. Then this is the same as the direct definition on $I_{\gamma'}$. Hence we have uniquely defined $\alpha + \beta$ for all $\beta$, since $\beta \in I_{\beta^+}$.

What about induction? Suppose we have some statement $p(\alpha)$ about an ordinal $\alpha$ such that for all $\alpha$, $(\forall \beta  \alpha, p(\beta)) \implies p(\alpha)$. Take an ordinal $\alpha$. By induction, for all $\gamma \in I_{\alpha^+}, p(\gamma)$. Hence $p(\alpha)$. So in fact $p(\alpha)$ holds for all ordinals $\alpha$.

\begin{lemma}
Let $\alpha, \beta, \gamma$ be ordinals. Then
\begin{enumerate}
\item $\beta \leq \gamma \implies \alpha + \beta \leq \alpha+\gamma$
\item $\beta < \gamma \implies \alpha + \beta < \alpha + \gamma$
\item $\gamma$ a non zero limit ordinal $\implies \alpha+\gamma$ a limit ordinal
\end{enumerate}
\end{lemma}
\begin{proof}
\item
\begin{enumerate}
\item We do this by induction on $\gamma$. If $\beta = \gamma$ then it is obvious, so assume $\beta < \gamma$. For $\gamma = 0$, there is no such $\beta$, so done. Otherwise, if $\gamma=  \delta^+, \beta < \delta^+ \implies \beta \leq \delta \implies \alpha + \beta \leq \alpha + \delta < (\alpha + \delta)^+ = \alpha + \delta^+ = \alpha+\gamma$. The final case is $\gamma$ is a non-zero limit. Then $\beta < \gamma \implies \alpha+\gamma = \sup\{\alpha + \delta : \delta < \gamma\} \geq \alpha+\beta$.

\item Suppose $\beta < \gamma$. Then $\beta^+ \leq \gamma$, so $\alpha + \beta < (\alpha + \beta)^+ = \alpha +\beta^+ \leq \alpha +\gamma$.

\item Suppose instead that $\alpha + \gamma = \delta^+$ for some $\delta$. Then $\delta < \alpha + \gamma = \sup\{\alpha + \epsilon : \epsilon < \gamma\}$, so $\delta < \alpha + \epsilon$ for some $\epsilon < \gamma$. As $\gamma$ is a limit, then $\epsilon^{+} < \gamma$. Then $\alpha + \gamma = \delta^+ \leq (\alpha + \epsilon)^+ = \alpha + \epsilon^+ < \alpha + \gamma$ by \textit{2.}. \contr
\end{enumerate}
\end{proof}
\begin{proposition}
Let $\alpha, \beta, \gamma$ be ordinals. Then $(\alpha+\beta)+\gamma = \alpha + (\beta + \gamma)$
\end{proposition}
\begin{proof}
We use induction on $\gamma$. In the case $\gamma = 0, (\alpha + \beta) + 0 = \alpha + \beta = \alpha + (\beta + 0)$.

If $\gamma = \delta^+$, then $(\alpha + \beta) + \delta^+ = ((\alpha+\beta) + \delta)^+ = (\alpha + (\beta + \delta))^+ = \alpha + (\beta+\delta)^+ = \alpha + (\beta+ \delta^+)$.


If $\gamma$ is a non-zero limit, then $(\alpha + \beta) + \gamma = \sup(X)$ where $X = \{(\alpha+\beta)+\delta : \delta < \gamma\} = \{\alpha + (\beta+\delta) : \delta < \gamma\}$. Meanwhile, by \textbf{2.10} part 3, $\beta + \gamma$ is a limit, and so $\alpha + (\beta+ \gamma) = \sup(Y)$ where $Y = \{\alpha + \epsilon : \epsilon < \beta + \gamma\}$. If $\delta < \gamma$ then by \textbf{2.10} part 2, $\beta+ \delta < \beta + \gamma$ so $X \subset Y$, and so $(\alpha + \beta) + \gamma \leq \alpha + (\beta+\gamma$. On the other hand, if $\zeta \in Y$, then $\zeta = \alpha + \epsilon$ for some $\epsilon < \beta + \gamma = \sup\{\beta + \delta : \delta  < \gamma\}$. Hence $\epsilon \leq \beta + \delta$ for some $\delta < \gamma$. Let $\eta = \alpha + (\beta + \delta)$. Then \textbf{2.10} part 1, $\eta \geq \zeta$ and also $\eta \in X$. Hence $\sup(X) \geq \sup(Y)$, so $(\alpha + \beta) + \gamma \geq \alpha + (\beta+\gamma)$, and so $(\alpha+\beta)+\gamma = \alpha +(\beta+\gamma)$.
\end{proof}

The definition in this section is the \emph{inductive} definition of arithmetic, whilst the one in the previous section was the \emph{synthetic} definition. It is often better to work with the synthetic definition than the inductive one. Fortunately however, they coincide.

\begin{proposition}
The synthetic and inductive definitions of ordinal addition coincide.
\end{proposition}
\begin{proof}
Let $+$ denote the synthetic definition. Then for all $\alpha$, $\alpha + 0 = \alpha$, and also $\alpha+\beta^+ = \leftarrow \alpha \rightarrow \leftarrow \beta \rightarrow \cdot = (\alpha+\beta)^+$

Finally, if $\alpha$ is an ordinal and $\gamma$ is a non-zero limit ordinal,t ehn $\alpha + \gamma = \leftarrow \alpha \rightarrow \leftarrow \sup\{\delta:\delta<\gamma\}\rightarrow = \sup(\alpha+\delta: \delta <\gamma\}$, by noting that $\delta$ is the order type of $I_{\delta}$, and the $I_{\delta}$ are nested so $\sup \leftrightarrow \cup$.

Hence by induction on $\beta$ the definitions agree on $\alpha + \beta$.
\end{proof}
\begin{proposition}
The synthetic and inductive definitions of ordinal multiplication coincide.
\end{proposition}
\begin{proof}
Left as an exercise for sheet 2.
\end{proof}

Can we define ordinal exponentiation? It's clear what to do inductively, but not so much synthetically. We define:
\begin{itemize}
\item $\alpha^0 = 0^+$
\item $\alpha^{\delta^+} = \alpha^{delta}\alpha$
\item $\alpha^{\beta}$ for $\beta$ a non-zero limit to be $\sup\{\alpha^\delta: \delta<\beta\}$.
\end{itemize}

\subsection{Uncountable Ordinals}
In \textbf{\textsection 1.4} our list of indices $0,1,2,\ldots, \omega,\ldots, \omega 2, \ldots, \epsilon_0$ are some ordinals. We've found lots of them, but in fact only countably many - $\epsilon_0 = \sup\{\omega, \omega^{\omega},\ldots\}$. Since $\alpha$ is the order type of $I_{\alpha}$, equivalently each of these ordinals is countable. However, there are more:
\begin{proposition}
There exists an uncountable ordinal.
\end{proposition}
\begin{proof}
Let $X \subset \powset(\N \times \N)$ be the set of all well-orderings of subsets of $\N$. Let $Y = \{\ord(x)  : x \in X\}$. Then $Y$ is precisely the set o countable ordinals. Let $\omega_1 = \sup(Y)$. Suppose $\omega_1$ is countable. Then $\omega_1 \in Y$ and the proper initial segment $Y_{(<\omega_1)}$ has the same order type as $Y$. \contr
\end{proof}
A couple of remarks:
\begin{itemize}
\item $\omega_1$ is the least uncountable ordinal.
\item The ordinal $\omega_1$ is not the supremum of any countably set of countable ordinals. Indeed, if $Z$ is a countable set of countable ordinals, then $\sup Z$ is the order-type of $\bigcup_{\alpha \in Z}I_{\alpha}$, a countable union of countable sets.
\end{itemize}
\begin{theorem}
Let $S$ be a set. Then there exists an ordinal $\gamma$ with no injection $\gamma \to S$.
\end{theorem}
\begin{proof}
Same as the previous proposition with $\N$ replaced by $S$.
\end{proof}
Theorem \textbf{2.15} is called \emph{Hartog's Lemma}. This makes sense of the statement in \textbf{\textsection 1.4} that we eventually run out of stuff, with a formal proof to follow in the next section.

\section{Posets and Zorn's Lemma}
A \emph{\underline{p}artially \underline{o}rdered \underline{set} (poset)} is a set $P$ with a relation $\leq$ satisfying:
\begin{enumerate}
\item $(x\leq y, y\leq z) \implies x \leq z$
\item $\forall x \in P, x\leq x$
\item $(x\leq y, y\leq x) \implies y = x$
\end{enumerate}
If $(P, \leq)$ is a poset and we define $x<y$ to mean $x \leq y$ and $x \neq y$, then
\begin{enumerate}
\item $(x<y, y<z) \implies x < z$
\item $x \nless x$
\end{enumerate}

Conversely, we can check that if $P$ is a set and $<$ is a relation on $P$ satisfying the above then $\leq$ gives a partial order on $P$. We use $>, \geq$ in the obvious way.

A \emph{Hasse diagram} of $(P, \leq)$ consists of a point for each $x \in P$ and line upwards from $x$ to $y$ if $y$ \emph{covers} $x$, i.e. that $y > x$ and there is no $z$ with $y > z > x$.

\hspace*{-1em}\underline{Examples}
\begin{enumerate}
\item Any totally ordered set is a poset.
\item Any subset of a poset is a poset.
\item For any set $X$, $\powset(X)$ is a poset under inclusion.
\item In a similar vein, take $\N$ with $|$ (divides). This is a poset.
\item We have the finite set with Hasse diagram given by:
\begin{center}
\begin{tikzpicture}
\node[circle, fill] (a) at (0,3) {};
\node[circle, fill] (b) at (-1,2) {};
\node[circle, fill] (c) at (0,2) {};
\node[circle, fill] (d) at (1,2) {};
\node[circle, fill] (e) at (0,1) {};
\node[circle, fill] (f) at (1,1) {};
\node[circle, fill] (g) at (0,0) {};
\draw (a) -- (b) -- (g);
\draw (a) -- (c) -- (e) -- (g);
\draw (a) -- (d) -- (f) -- (g);
\end{tikzpicture}
\end{center}
\end{enumerate}

Let $(P, \leq)$ be a poset. We say that $x \in P$ is \emph{greatest} if for all $y \in P, y \leq x$. We say that $x \in P$ is \emph{maximal} if for all $y \in P$, $y \geq x \implies y = x$. If $S \subset P$, an \emph{upper bound} for $S$ is an $x \in P$ such that $y \in S \implies y \leq x$. We can similarly define \emph{least}, \emph{minimal}, and \emph{lower bound}. If $S$ has a least upper bound we denote it by $\sup(S)$ or by $\bigvee S$, read ``join $S$". Similarly, if we have a greatest lower bound or infimum of $S \subseteq P$, we denote it by $\inf(S)$ or $\bigwedge S$, read ``meet $S$". We have the diagram:
\begin{center}
\begin{tikzpicture}
\node[circle, draw, minimum size=3em] (v) at (0,2) {$a \vee b$};
\node[circle, draw, minimum size=3em] (a) at (-2,0) {$a$};
\node[circle, draw, minimum size=3em] (b) at (2,0) {$b$};
\node[circle, draw, minimum size=3em] (n) at (0,-2) {$a \wedge b$};
\draw (v) -- (a) -- (n) (v) -- (b) -- (n);
\end{tikzpicture}
\end{center}
\hspace*{-1em}\underline{Examples:}
\begin{enumerate}
\item In $(\powset S, \subseteq)$, $S$ is greatest and $\emptyset$ is least.
\item In $(\N, \leq)$, $0$ is least. There is no greatest or maximal element.
\item Take the finite set with diagram given by:\\
\begin{minipage}{0.2\textwidth}
\centering
\begin{tikzpicture}
\node[circle, draw] (a) at (-0.7,1) {$a$};
\node[circle, draw] (b) at (0.7,1) {$b$};
\node[circle, draw] (c) at (0,0) {$c$};
\draw (a) -- (c) (b) -- (c);
\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.5\textwidth}
We have $a$ is maximal, but $a$ is not greatest since $a \ngeq b$. $b$ is maximal as well. $c$ is both minimal and least.
\end{minipage}
\end{enumerate}
Note that $a$ greatest implies that $a$ is maximal, and if $P$ has a greatest element then it must be unique. If every subset of $P$ has a supremum then we say that $P$ is \emph{complete}. If $P$ is complete then $P$ is non-empty, as $\bigvee\emptyset \in P$. In fact, $\bigvee\emptyset$ is the least element of $P$. $P$ also has a greatest element, $\bigvee P$.

\hspace*{-1em}\underline{Examples:}
\begin{enumerate}
\item $(\powset S, \subseteq)$ is complete. $\bigvee \mathcal{A} = \bigcup_{A \in \mathcal{A}} A, \bigwedge \mathcal{A} = \bigcap_{A \in \mathcal{A}} A$.
\item $([0,1], \leq)$ is complete.
\item $(\R, \leq)$ is not complete.
\end{enumerate}
If $(P, \subseteq)$ is a poset then a \emph{chain} is a subset $C \subseteq P$ such that for all $x, y \in C$ either $x \leq y$ or $y \leq x$. If every chain has a supremum, we say that $P$ is \emph{chain-complete.} Note again that chain complete implies nonempty since the empty set is a chain.

\hspace*{-1em}\underline{Examples:}
\begin{enumerate}
\item In $(\N,1)$, the set $\{4^n : n \in \N\}$ is a chain.
\item In $(\R, \leq)$, $\Q$ is a chain, and so is $\R$.
\end{enumerate}

A \emph{lattice} $L$ is a poset in which every finite subset has both a supremum and an infimum. For $a, b \in L$, we write $a \vee b = \bigvee \{a, b\}$ and $a \wedge b = \bigwedge \{a, b\}$. Note that $L$ has a least element $\bigwedge \emptyset$ and a greatest element $\bigvee \emptyset$. We say that a lattice $L$ is a \emph{Boolean algebra} if:
\begin{enumerate}
\item For all $a,b,c \in L$, $a \wedge (b \vee c) = (a \wedge b)\vee(a \wedge c)$
\item For all $a,b,c \in L$, $a \vee (b \wedge c) = (a \vee b) \wedge (a \vee c)$
\item For all $a \in L$ there is $b \in L$, $a \vee b = \bigwedge \emptyset, a \wedge b = \bigvee \emptyset$
\end{enumerate}
These rules are essentially saying $L$ behaves like a powerset, with $\wedge$ corresponding to $\cap$ and $\vee$ corresponding to $\cup$. Then the first two rules are de Morgan's laws, and the third is the notion of a complement.

\subsection{Zorn's Lemma}
\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=5]
\tikzset{rotate=-45}
\fill [MaterialYellow500] (0, 0) ellipse [x radius=1/3, y radius=  1];
\fill [MaterialYellow500] (0, 0) ellipse [x radius=3/4, y radius=7/8];
\fill [MaterialYellow600] (270:1/3 and   1) arc (270:450:1/3 and   1);
\fill [MaterialYellow600] (270:3/4 and 7/8) arc (270:450:3/4 and 7/8);
\begin{scope}[shift=(90:9/10), rotate=-135]
\fill [MaterialGreen500] 
  (0,0) arc (45:135:1/2 and 4/5) arc (225:315:1/2 and 3/5);
\fill [MaterialGreen700] 
  (0,0) arc (45:135:1/2 and 4/5) -- cycle;
\tikzset{rotate=90, scale=3/4}
\fill [MaterialGreen500] 
  (0,0) arc (45:135:1/2 and 4/5) arc (225:315:1/2 and 3/5);
\fill [MaterialGreen700] 
  (0,0) arc (45:135:1/2 and 4/5) -- cycle;
\end{scope};
\end{tikzpicture}
\caption{Zorn's Lemon}
\end{figure}
\begin{theorem}[Zorn's Lemma]
Let $(P, \leq)$ be a poset in which every chain has an upper bound. Then $P$ has a maximal element.
\end{theorem}
The idea is that, if not, we can take $x_0$ to be the upper bound of the empty set, then if $x_0$ is not maximal there is $x_1 > x_0$, and then we get another chain indexed by the ordinals, and eventually run out of stuff.
\begin{proof}
Suppose $P$ has no maximal element. Then for any $x \in P$, we can find $x' \in P$ with $x' > x$. Moreover, for any chain $C \subseteq P$ we can find $C^{\ast} \in P$ such that for all $x \in C$, $C^{\ast} > x$, for instance take $y$ to be an upper bound for $C$ and let $C^{\ast} = y'$.

By Hartog's Lemma, we can find an ordinal $\gamma$ such that there is no injection from $\gamma \to P$.

Recursively for $\alpha < \gamma$ define $x_{\alpha}$ as follows:
\begin{itemize}
\item[$\alpha=0$:] $x_0 = \emptyset^{\ast}$ - we can use any element of $P$
\item[$\alpha=\beta^+:$] $x_{\beta^+} = x_{\beta}'$
\item[Otherwise:] $\alpha$ is a non-zero limit, so let $x_{\alpha} = \{x_{\delta} : \delta < \alpha\}^{\ast}$.
\end{itemize}
We can do this because $\{x_\delta : \delta < \alpha\}$ is a chain as $x_{\zeta} > x_{\xi} \iff \zeta > \xi$, and the ordinals are totally ordered.

Then $\alpha \mapsto x_{\alpha}$ is an injection $I_\gamma \to P$, and $I_\gamma \cong \gamma$. \contr
\end{proof}
But can we actually let $x_{\alpha} = \{x_{\delta} : \delta < \alpha\}^{\ast}$? Even though we know the thing on the right is a chain, we don't know that until we're halfway through the recursion - when we define what $x_\alpha$ will be, we are saying its the star of something that may or may not be a chain. It is only once we find out what this something is that we know it is indeed a chain and we can take a star of it, and this first assignment is slightly dodgy. To get around this, we use the technical fix of cabbages:

\textbf{Cabbages.} Take something not in $P$, for instance a cabbage that we happen to have lying around. For $\alpha < \gamma$, define $x_\alpha \in P\cup \{$cabbage$\}$ exactly as above, except for $\alpha$ a non-zero limit.

Then set for $\alpha$ a non-zero limit, let $x_\alpha = \begin{cases} \{x_\delta:\delta<\alpha\}^{\ast} & \text{this set is a chain}\\ \text{cabbage} & \ow\end{cases}$, and also define cabbage$' = $ cabbage. By induction, we don't get any cabbage. In these proofs, cabbages are implicitly assumed.

\subsection{Applications of Zorn's Lemma}
The general method of applying Zorn's Lemma is as follows:
\begin{enumerate}
\item Define a suitable poset.
\item Check every chain has an upper bound.
\item Use Zorn to find a maximal element $x$.
\item Check $x$ is the thing we are looking for.
\end{enumerate}
It is not unusual for most of the work to come in step 4.
\begin{corollary}
Let $P$ be a set of primitive propositions, and let $S \subset L = L(P)$ be consistent. Then there is a consistent $\bar{S} \subset L$ with $S \subset \bar{S}$ and for all $p \in L$, $p \in \bar{S}$ or $\neg p \in \bar{S}$.
\end{corollary}
\begin{proof}
Let $X$ be the poset  $\{R\subset L | R$ consistent and $S \subset R\}$, ordered by $\subset$. Let $\mathscr{C} \subset X$ be a chain. If $\mathscr{C} = \emptyset$ then $S \in X$ is an upper bound for $\mathscr{C}$. 

Suppose $\mathscr{C} \neq \emptyset$. Let $Q = \bigcup_{R \in \mathscr{C}} R$. Then for all $R \in \mathscr{C}, R \subset Q$. As $\mathscr{C} \neq \emptyset$, there exists $R \in \mathscr{C}$ and $S \subset R \subset Q$. Suppose that $Q$ is inconsistent, i.e. that $Q \vdash \bot$. As proofs are finite, there are some $q_1, \ldots, q_n \in Q$ such that $\{q_1, \ldots, q_n\}\vdash\bot$. For each $i$, pick $R_i \in \mathscr{C}$ with $q_i \in R_i$. As $\mathscr{C}$ is a chain and there are only finitely many of $R_1, \ldots, R_n$, there exists $j$ such that $R_i \subseteq R_j$ for all $i$. Then $q_1, \ldots, q_n \in R_j$, and so $R_j \vdash \bot$. \contr

Hence $Q$ is consistent. Thus $Q \in X$ is an upper bound for $\mathscr{C}$. By Zorn's lemma, $X$ has a maximal element $\bar{S}$. Let $p \in L$ and suppose $p \notin \bar{S}$. Then $\bar{S} \cup \{p\}$ is inconsistent, as otherwise $\bar{S} \cup \{p\} \in X$ with $\bar{S} \subsetneq \bar{S}\cup\{p\}$. That is, $\bar{S}\cup\{p\} \vdash \bot$, and so by the deduction theorem $\bar{S} \vdash (p \implies \bot)$, i.e. $\bar{S} \vdash \neg p$. So, similarly to the above, $\neq p \in \bar{S}$.
\end{proof}
This fills the gap in the proof of the Model Existence Lemma, thus finishing the proof of the completeness theorem. It is very common when using Zorn to consider a poset of the form $(X, \subseteq)$ where $X \subseteq \powset(A)$ for some set $A$. If $\mathscr{C}$ is a chain in $X$, an obvious guess for an upper bound for $\mathscr{C}$ is $Q = \bigcup_{R \in \mathscr{C}} R$. Clearly for all $R \in \mathscr{C}$, $R \subseteq Q$, but often work is needed to show that $Q \in X$, so that $Q$ is genuinely an upper bound for $\mathscr{C}$ in $X$. Also, care must be taken to remember that $\emptyset$ si a chain, and often needs t be considered separately.

\begin{corollary}
Every vector space has a basis.
\end{corollary}
\begin{proof}
Let $V$ be a vector space over a field $k$. Let $P = \{S \subseteq V | S$ is linearly independent$\}$, ordered by $\subseteq$. Let $\mathscr{C} \subseteq P$ be a chain, and let $R = \bigcup_{S \in \mathscr{C}}S$. Suppose that $R$ is linearly dependent. Then there are some $n \in \N\setminus\{0\}$, and some distinct $v_1, \ldots, v_n \in R$ and some $\lambda_1, \ldots, \lambda_n \in k$ with $\sum_{i=1}^n \lambda_i v_i = 0$. For each $i$, pick $S_i \in \mathscr{C}$ with $v_i \in S_i$. As $\mathscr{C}$ is a chain, there is some $j$ for which $S_i \subseteq S_j$ for all $i =1, \ldots, n$. Then $v_1, \ldots, v_n \in S_j$ , so $S_j$ is linearly dependent. \contr

Hence $R$ is linearly independent, and so $R$ is an upper bound for $\mathscr{C}$. By Zorn, $P$  has a maximal element $B$. Certainly $B$ is linearly independent. Suppose there is some $v \in V \setminus \spann{B}$. We show that $B \cup\{v\}$ is linearly independent. Indeed, if not then we have a linear combination $\mu v - \sum_{i=1}^n \lambda_i b_i = 0$, where $b_i \in B$, but then $v = \sum \mu^{-1}\lambda_i b_i \in \spann{B}$\contr. But then $B\cup\{v\} \in P$, and $B \subsetneq B\cup\{v\}$, \contr maximality of $B$.

So $B$ is a linearly independent set spanning $V$, and so $B$ is a basis for $V$.
\end{proof}

\begin{corollary}[Bourbaki-Witt Theorem]
Let $(X, \leq)$ be a poset, and let $X$ be chain-complete, and $f: X \to X$ be such that for all $x \in X, f(x) \geq x$. Then $f$ has a fixed point.
\end{corollary}
\begin{proof}
By Zorn $X$ has a maximal element $x$. Then $f(x) \in X, f(x) \geq x$, so by maximality $f(x) = x$.
\end{proof}

\begin{corollary}[Well-Ordering Principle]
Every set can be well-ordered.
\end{corollary}
\begin{proof}
Let $X$ be a set. Let $P = \{(Y,R) | Y\subset X$ and $R$ is a well-ordering of $Y\}$. Define $(Y,R)\leq (Z,S)$ if $Y \subset Z$ and $R,S$ agree on $Y$, and $Y$ is an initial segment of $Z$ in $S$. Then $(P, \leq)$ is a poset. Let $\mathscr{C} \subset P$ be a chain, say $\mathscr{C} = \{(Y_i, R_i) | i \in I\}$. Let $Y = \bigcup_{I \in I} Y_i$. Define a relation $R$ on $Y$ as follows: if $x,y \in Y$ then choose $j, k \in I$ such that $x \in Y_j$ and $y \in Y_k$. If $Y_j \subset Y_K$ then $xRy \iff xR_k y$, otherwise $Y_k \subset Y_j$ in which case $xRy \iff xR_j y$.

It is easy to show that $R$ is a total ordering of $Y$. We must show further that it is a well ordering. Let $A \subset Y$ with $A \neq \emptyset$. Then there exists $x \in A$, so $x \in Y_{\ell}$ for some $\ell \in I$, so $A \cap Y_{\ell} \neq \emptyset$. But we know $Y_{\ell}$ is well ordered by $R_{\ell}$, so $A \cap Y_{\ell}$ has an $R_\ell$-least element, $z$, say. So $z$ is also the $R$-least element of $A \cap Y_\ell$, and hence $R$ is a well ordering of $Y$.

Thus, $(Y,R) \in P$ and is an upper bound for $\mathscr{C}$. Then by Zorn, $P$ has a maximal element $(Z,S)$. Suppose there is some $x \in X \setminus Z$. Then $S \cup \{(z, x) | z \in Z \cup \{x\}\}$ is a well ordering of $Z \cup \{x\} \supsetneq Z$, and $Z$ is an initial segment. \contr

Hence $Z = X$ and $S$ is a well ordering of $X$.
\end{proof}
\subsection{The Axiom of Choice}
In the proof of Zorn's Lemma (ZL), we had to make infinitely many arbitrary choices, e.g. for all $x \in X$, pick some $x' > x$. We've done this quite a bit throughout tripos, for instance in IA Numbers and Sets, when we proved that a countable union of countable sets is countable by picking an ordering of each set so that we can move along the list diagonally.

\begin{axiom}[The Axiom of Choice]
Let $\{X_i | i \in I\}$ be a set of non-empty sets. Then there exists a function $f: I \to \bigcup_{i \in I}X_i$ such that, for all $i \in I$, $f(i) \in X_i$.
\end{axiom}
The function $f$ is sometimes called a \emph{choice function} for the collection $\{X_i|i \in I\}$.

The axiom of choice (AC) has a different feel from our other usual assumptions about sets, e.g. it doesn't explicitly construct anything, so it can be of interest to see if we've used it. For example we used AC when proving Zorn's Lemma, but it might be an interesting question to ask if we needed to. What does this even mean? To give a sensible answer, we'd need to axiomatise set theory, and think about proof systems, and then show that if we only assume axioms other than AC then Zorn's Lemma would no longer be a theorem. This would take a lot of work (c.f. Russell and Whitehead, Principia Mathematica). For now, we will do a similar thing - assume Zorn's Lemma and use it to prove AC.
\begin{proof}
Let $\{X_i | i \in I\}$ be a collection of non-empty sets, and let
\begin{align*}
P = \left\{\left.g \subset \powset\left(I \times \bigcup_{i \in I} X_i \right) \right| g:J\to \bigcup_{i\in I}X_i, J \subseteq I; \forall i \in \dom(g), g(i) \in X_i\right\}
\end{align*}
ordered by inclusion. Not $g \subset g'$ means $\dom g \subset \dom g'$ and $g'|_{\dom g} = g$. Let $\mathscr{C}$ be a chain in $P$. Let $h = \bigcup_{g \in \mathscr{C}} g$. Then $h$ is a function with $\dom h = \bigcup_{g\in \mathscr{C}} \dom g$.

Moreover, $h \in P$ and is an upper bound for $\mathscr{C}$. So by Zorn $P$ has a maximal element $f$. Suppose $i \in I \setminus \dom f$. Pick $x \in X_i$\footnote{We can do this without using AC since we are only making one choice, and that is precisely what it means for a set to be nonempty - we can pick an element from it}. Then $f \subsetneq f \cup \{(i, x)\} \in P$. \contr
So $f$ is our required choice function.
\end{proof}
\end{document}
